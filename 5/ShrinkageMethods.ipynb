{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shrinkage methods for linear regression models \n",
    "\n",
    "In this lesson we are going to learn how to:\n",
    "\n",
    "1. Estimate a ridge regression model with fixed penalty term\n",
    "2. Estimate a lasso regression model with fixed penalty term\n",
    "3. Cross-validate the penalty terms both for the ridge regression and the lasso\n",
    "4. Compare a simple linear regression model against both the ridge and the lasso regression models\n",
    "\n",
    "As usual, the first step is to import the data by using the **pandas** package. The data refers to median house prices in a metropolitan area in the US. In addition to the target variable, median house price for a given are, we also have a set of predictors such as the portion of the house built before 1940 (**age**), number of rooms (**rm**), per capita crime rate (**crim**) and tax rate (**tax**). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('Boston.csv',index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate a linear regression model\n",
    "\n",
    "As a first step, we are going to estimate a linear regression model. This is going to be our baseline model against which we compare the ridge and the lasso. To estimate the linear regression we are going to use the ***sklearn*** package. Since we are interested in forecasting, and ultimately to assess the performance of a linear regression model out of sample, we need to split the train vs testing observations. This is done using the ***train_test_split*** function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define and standardise the predictors\n",
    "X       = df[['rm','nox','indus','crim','tax','ptratio','lstat','age','dis']]\n",
    "X       = StandardScaler().fit_transform(X)\n",
    "\n",
    "# Define and standardise the target variables\n",
    "y       = df['medv'].values.reshape(-1,1)\n",
    "y       = StandardScaler().fit_transform(y)\n",
    "\n",
    "# Split the whole data in train vs test data. We take a third of the data as testing sample. \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Define and estimate the model\n",
    "lr       = LinearRegression(fit_intercept = False).fit(X_train, y_train)\n",
    "\n",
    "ypred_lr = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calcolate now the forecasting performance based on the $R^2$ coefficient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ols': {'r2 ': 0.7}}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2_lr = round(r2_score(y_test, ypred_lr),2)\n",
    "\n",
    "accuracy = {'ols': {'r2 ': r2_lr}} #creating a dictionary\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate a ridge regression model\n",
    "\n",
    "We now estimate a ridge regression model with a fixed penalty parameter. Notice in the python syntax, the penalty term $\\lambda$ is called ***alpha***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "alpha = 10 # This is the penalty term\n",
    "ridge = Ridge(alpha = alpha, fit_intercept = False) # Normalise means that the predictors are \n",
    "ridge.fit(X_train,y_train)\n",
    "\n",
    "ypred_ridge = ridge.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ols': {'r2 ': 0.7}, 'ridge': 0.7}\n"
     ]
    }
   ],
   "source": [
    "r2_ridge = round(r2_score(y_test, ypred_ridge),2)\n",
    "\n",
    "accuracy['ridge'] = r2_ridge\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate a lasso regression\n",
    "\n",
    "We now estimate a ridge regression model with a fixed penalty parameter. Notice in the python syntax, the penalty term $\\lambda$ is called ***alpha***. For simplicity, we use the same penalty term used for the ridge regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ols': {'r2 ': 0.7}, 'ridge': 0.7, 'lasso': 0.65}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "alpha = 0.1 # This is the penalty term\n",
    "lasso = Lasso(alpha = alpha, fit_intercept = False) \n",
    "lasso.fit(X_train,y_train)\n",
    "\n",
    "ypred_lasso = lasso.predict(X_test)\n",
    "\n",
    "r2_lasso = round(r2_score(y_test, ypred_lasso),2)\n",
    "\n",
    "accuracy['lasso'] = r2_lasso\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now collect the results across models and compare the performances. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ols  ridge  lasso\n",
      "r2   0.7    0.7   0.65\n"
     ]
    }
   ],
   "source": [
    "accuracy = pd.DataFrame(accuracy)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this level of shrinkage, $\\lambda=10$ the OLS seems to perform better than the others. We now try to estimate the penalty terms, instead of fixing them, via cross-validation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation of the penalty terms \n",
    "\n",
    "Cross validation of the penalty terms can be implemented via the function ***GridSearchCV***, both for the ridge and for the lasso regression models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "alpha_space    = np.linspace(1, 10, 20) # Here we explore a penalty term from 0.1 to 100\n",
    "param_grid = {'alpha': alpha_space}\n",
    "\n",
    "ridge_cv  = GridSearchCV(Ridge(fit_intercept = False), param_grid, cv = 5) \n",
    "#GridSearchCV use dictionary as argument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now fit the model and produce the corresponding forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_cv.fit(X_train, y_train)\n",
    "\n",
    "ypred_ridge_cv = ridge_cv.predict(X_test)\n",
    "\n",
    "r2_ridge_cv = round(r2_score(y_test, ypred_ridge_cv),2)\n",
    "\n",
    "accuracy['ridge cv'] = r2_ridge_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the same procedure for the lasso. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_space    = np.linspace(0.1, 2, 20) # Here we explore a penalty term from 0.1 to 2\n",
    "param_grid = {'alpha': alpha_space}\n",
    "\n",
    "lasso_cv  = GridSearchCV(Lasso(fit_intercept = False), param_grid, cv = 5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_cv.fit(X_train, y_train)\n",
    "\n",
    "ypred_lasso_cv = lasso_cv.predict(X_test)\n",
    "\n",
    "r2_lasso_cv = round(r2_score(y_test, ypred_lasso_cv),2)\n",
    "\n",
    "accuracy['lasso cv'] = r2_lasso_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ols</th>\n",
       "      <th>ridge</th>\n",
       "      <th>lasso</th>\n",
       "      <th>ridge cv</th>\n",
       "      <th>lasso cv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>r2</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ols  ridge  lasso  ridge cv  lasso cv\n",
       "r2   0.7    0.7   0.65       0.7      0.65"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Penalty term for the ridge regression: \n",
      " Ridge(alpha=10.0, fit_intercept=False)\n",
      "Penalty term for the lasso regression: \n",
      " Lasso(alpha=0.1, fit_intercept=False)\n"
     ]
    }
   ],
   "source": [
    "print('Penalty term for the ridge regression: \\n', ridge_cv.best_estimator_)\n",
    "print('Penalty term for the lasso regression: \\n', lasso_cv.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
